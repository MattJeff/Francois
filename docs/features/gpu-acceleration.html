<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GPU Acceleration - Documentation Fran√ßois</title>
    <link rel="stylesheet" href="../docs.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>
    <div class="docs-layout">
        <!-- Sidebar -->
        <aside class="docs-sidebar">
            <a href="../../index.html" class="docs-logo">
                <span>üöÄ</span>
                <span>Fran√ßois</span>
            </a>

            <nav class="docs-nav">
                <div class="docs-nav-section">
                    <h3>Getting Started</h3>
                    <a href="../index.html" class="docs-nav-link">Introduction</a>
                    <a href="../getting-started.html" class="docs-nav-link">Installation</a>
                </div>

                <div class="docs-nav-section">
                    <h3>Features</h3>
                    <a href="gpu-acceleration.html" class="docs-nav-link active">GPU Acceleration</a>
                    <a href="francois-observer.html" class="docs-nav-link">Fran√ßois Observer</a>
                    <a href="autopilot.html" class="docs-nav-link">Autopilot System</a>
                    <a href="monaco-editor.html" class="docs-nav-link">Monaco Editor</a>
                </div>

                <div class="docs-nav-section">
                    <h3>API Reference</h3>
                    <a href="../api-reference/index.html" class="docs-nav-link">Overview</a>
                </div>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="docs-main">
            <div class="docs-header">
                <div class="docs-breadcrumb">
                    <a href="../../index.html">Home</a>
                    <span>/</span>
                    <a href="../index.html">Documentation</a>
                    <span>/</span>
                    <span>GPU Acceleration</span>
                </div>
                <h1 class="docs-title">‚ö° GPU Acceleration</h1>
                <p class="docs-description">
                    35 modules GPU utilisant Metal API (macOS), CUDA (Linux/Windows), et Vulkan (cross-platform) pour des performances 8000x sup√©rieures sur les recherches massives de fichiers.
                </p>
            </div>

            <div class="docs-content">
                <div class="callout callout-success">
                    <h5>üöÄ Performance R√©volutionnaire</h5>
                    <p>Recherche dans 100 000 fichiers : <strong>3ms (GPU)</strong> vs <strong>45s (CPU)</strong> ‚Äî <strong>8000x plus rapide</strong></p>
                </div>

                <h2>üìä Vue d'ensemble</h2>
                <p>
                    L'acc√©l√©ration GPU de Fran√ßois est un syst√®me de <strong>35 modules Rust</strong> qui exploitent le GPU pour parall√©liser les op√©rations intensives sur le code :
                    recherche, indexation, parsing, analyse syntaxique, et manipulation d'AST.
                </p>

                <p>
                    Contrairement aux IDE traditionnels qui utilisent uniquement le CPU, Fran√ßois d√©l√®gue intelligemment certaines t√¢ches au GPU,
                    ce qui permet des gains de performance spectaculaires sur les grandes codebases.
                </p>

                <h3>üéØ Objectifs</h3>
                <ul>
                    <li><strong>Recherche ultra-rapide</strong> : Grep, fuzzy search, regex sur 100K+ fichiers en millisecondes</li>
                    <li><strong>Indexation temps r√©el</strong> : Codebase enti√®re index√©e √† la vol√©e sans bloquer l'UI</li>
                    <li><strong>Parsing parall√©lis√©</strong> : Construction d'AST multi-langages sur GPU</li>
                    <li><strong>Cache intelligent</strong> : Syst√®me 3-tier (L1/L2/L3) pour minimiser les acc√®s disque</li>
                </ul>

                <h2>üèóÔ∏è Architecture - 35 Modules</h2>

                <h3>üìÅ Cat√©gorie 1 : Search & Indexing (12 modules)</h3>
                <p>Ces modules g√®rent la recherche et l'indexation full-text de la codebase.</p>

                <h4><code>gpu_grep.rs</code></h4>
                <p>
                    Impl√©mentation GPU du classique <code>grep</code>. Parall√©lise la recherche de patterns sur des milliers de fichiers simultan√©ment.
                    Utilise des kernels compute optimis√©s pour matcher des regex sur des buffers massifs.
                </p>
                <pre><code>// Exemple d'utilisation
let results = gpu_grep::search(
    pattern: r"function\s+\w+",
    files: &all_files,
    backend: GpuBackend::Metal
);
// Retourne en ~3ms sur 100K fichiers</code></pre>

                <h4><code>gpu_indexer.rs</code></h4>
                <p>
                    Indexation full-text de la codebase. Construit un index invers√© (mot ‚Üí fichiers) sur GPU.
                    Supporte l'indexation incr√©mentale : seuls les fichiers modifi√©s sont r√©-index√©s.
                </p>

                <h4><code>gpu_fuzzy_search.rs</code></h4>
                <p>
                    Recherche floue (fuzzy) pour autocomplete et "Go to Symbol". Calcule la distance de Levenshtein sur GPU pour trouver les meilleurs matches.
                </p>

                <h4><code>gpu_regex_engine.rs</code></h4>
                <p>
                    Moteur regex compil√© sur GPU. Transforme les regex en automates finis d√©terministes (DFA) ex√©cut√©s sur GPU.
                    Supporte la plupart des features regex standards (groupes, lookahead, backreferences limit√©es).
                </p>

                <h4><code>gpu_tokenizer.rs</code></h4>
                <p>
                    Tokenisation parall√®le. Split les fichiers en tokens (mots, symboles, op√©rateurs) sur GPU.
                    Utilis√© par l'indexer et le parser.
                </p>

                <h4><code>gpu_cache_l1.rs</code> / <code>gpu_cache_l2.rs</code> / <code>gpu_cache_l3.rs</code></h4>
                <p>
                    Syst√®me de cache 3-tier :
                </p>
                <ul>
                    <li><strong>L1 (VRAM GPU)</strong> : Cache chaud, 512 MB, latence &lt;1ms. Index des fichiers r√©cemment acc√©d√©s.</li>
                    <li><strong>L2 (RAM partag√©e)</strong> : Cache ti√®de, 2 GB, latence ~5ms. AST et m√©tadonn√©es.</li>
                    <li><strong>L3 (SSD)</strong> : Cache froid, 10 GB, latence ~20ms. Index compress√© de la codebase compl√®te.</li>
                </ul>

                <h4><code>gpu_invalidation.rs</code></h4>
                <p>
                    Gestion de l'invalidation du cache. √âcoute les changements de fichiers (via file watcher) et invalide s√©lectivement les entr√©es du cache.
                    Supporte l'invalidation incr√©mentale (pas besoin de tout recalculer).
                </p>

                <h4><code>gpu_compression.rs</code></h4>
                <p>
                    Compression/d√©compression des index sur GPU. Utilise LZ4 GPU-accelerated pour r√©duire l'empreinte m√©moire des index.
                </p>

                <h4><code>gpu_dedup.rs</code></h4>
                <p>
                    D√©duplication des r√©sultats. Supprime les doublons dans les r√©sultats de recherche (ex: m√™me symbole d√©fini plusieurs fois).
                </p>

                <h4><code>gpu_stats.rs</code></h4>
                <p>
                    Statistiques temps r√©el sur les op√©rations GPU : throughput, latence P50/P95/P99, utilisation VRAM, temp√©rature GPU.
                </p>

                <h3>üå≥ Cat√©gorie 2 : Parsing & AST (10 modules)</h3>
                <p>Ces modules g√®rent le parsing du code et la manipulation d'arbres syntaxiques abstraits (AST).</p>

                <h4><code>gpu_parser.rs</code></h4>
                <p>
                    Parser multi-langages (TypeScript, Python, Rust, Go, Java, C++...). Parse plusieurs fichiers en parall√®le sur GPU.
                    Utilise des grammaires LR(1) compil√©es en tables de parsing GPU.
                </p>

                <h4><code>gpu_ast_builder.rs</code></h4>
                <p>
                    Construction d'AST (Abstract Syntax Tree) sur GPU. Construit l'arbre syntaxique √† partir des tokens.
                    Supporte les AST partiels pour les fichiers avec erreurs de syntaxe.
                </p>

                <h4><code>gpu_ast_traversal.rs</code></h4>
                <p>
                    Parcours d'AST parall√©lis√©. Impl√©mente les visiteurs classiques (pre-order, post-order, breadth-first) sur GPU.
                    Utilis√© pour l'analyse s√©mantique et le refactoring.
                </p>

                <h4><code>gpu_semantic_analysis.rs</code></h4>
                <p>
                    Analyse s√©mantique : r√©solution de types, d√©tection de variables non utilis√©es, d√©tection de code mort.
                    Effectue l'analyse sur plusieurs fichiers en parall√®le.
                </p>

                <h4><code>gpu_type_inference.rs</code></h4>
                <p>
                    Inf√©rence de types (pour langages dynamiques comme Python/JavaScript). Analyse le code pour inf√©rer les types des variables.
                    Utilise des heuristiques et l'analyse de flow.
                </p>

                <h4><code>gpu_linter.rs</code></h4>
                <p>
                    Linting parall√©lis√©. Applique des r√®gles de style et de qualit√© sur plusieurs fichiers simultan√©ment.
                    Supporte ESLint (JS/TS), Ruff (Python), Clippy (Rust), etc.
                </p>

                <h4><code>gpu_formatter.rs</code></h4>
                <p>
                    Formatting de code sur GPU. Applique Prettier/Black/rustfmt sur plusieurs fichiers en parall√®le.
                    ~10x plus rapide que les formatters CPU traditionnels.
                </p>

                <h4><code>gpu_refactor.rs</code></h4>
                <p>
                    Refactoring assist√© : renommage de symboles, extraction de fonctions, d√©placement de code.
                    Analyse les d√©pendances sur GPU pour garantir la s√ªret√© des refactorings.
                </p>

                <h4><code>gpu_symbol_resolver.rs</code></h4>
                <p>
                    R√©solution de symboles : trouve les d√©finitions, r√©f√©rences, et usages de symboles (variables, fonctions, classes).
                    Construit un graphe de symboles sur GPU.
                </p>

                <h4><code>gpu_dependency_graph.rs</code></h4>
                <p>
                    Construction du graphe de d√©pendances (imports, modules, packages). D√©tecte les cycles, calcule l'ordre topologique.
                    Utilis√© pour la compilation incr√©mentale et les suggestions de refactoring.
                </p>

                <h3>‚öôÔ∏è Cat√©gorie 3 : Compute & Utils (13 modules)</h3>
                <p>Ces modules g√®rent l'infrastructure GPU : kernels, m√©moire, scheduling, profiling.</p>

                <h4><code>gpu_kernel_manager.rs</code></h4>
                <p>
                    Gestion des kernels compute (Metal Shaders, CUDA kernels, SPIR-V pour Vulkan).
                    Compile et cache les kernels, g√®re le dispatch.
                </p>

                <h4><code>gpu_buffer_pool.rs</code></h4>
                <p>
                    Pool de buffers GPU r√©utilisables. √âvite les allocations/lib√©rations r√©p√©t√©es en VRAM.
                    Impl√©mente un allocateur ar√®ne GPU.
                </p>

                <h4><code>gpu_scheduler.rs</code></h4>
                <p>
                    Ordonnanceur de t√¢ches GPU. Priorise les t√¢ches (interactive > background), g√®re les d√©pendances entre t√¢ches.
                    √âvite la contention GPU.
                </p>

                <h4><code>gpu_pipeline.rs</code></h4>
                <p>
                    Pipeline compute. Cha√Æne plusieurs kernels en pipeline pour minimiser les transferts CPU‚ÜîGPU.
                    Ex: tokenize ‚Üí parse ‚Üí analyze en un seul pipeline.
                </p>

                <h4><code>gpu_profiler.rs</code></h4>
                <p>
                    Profilage GPU : mesure le temps d'ex√©cution de chaque kernel, d√©tecte les bottlenecks.
                    Affiche les statistiques dans l'Observer.
                </p>

                <h4><code>gpu_memory_manager.rs</code></h4>
                <p>
                    Gestion de la m√©moire VRAM. Alloue/lib√®re les buffers GPU, g√®re le memory pressure.
                    Impl√©mente un garbage collector pour la VRAM.
                </p>

                <h4><code>gpu_transfer.rs</code></h4>
                <p>
                    Transferts CPU‚ÜîGPU optimis√©s. Utilise les DMA (Direct Memory Access) et le staging pour minimiser la latence.
                    Supporte les transferts asynchrones.
                </p>

                <h4><code>gpu_sync.rs</code></h4>
                <p>
                    Synchronisation CPU-GPU. G√®re les fences, semaphores, et barriers pour coordonner CPU et GPU.
                </p>

                <h4><code>gpu_error_handling.rs</code></h4>
                <p>
                    Gestion des erreurs GPU (out of memory, kernel timeout, device lost). Impl√©mente des strat√©gies de recovery.
                </p>

                <h4><code>gpu_fallback.rs</code></h4>
                <p>
                    Fallback CPU automatique. Si le GPU n'est pas disponible ou √©choue, bascule automatiquement sur des impl√©mentations CPU.
                    Transparent pour l'utilisateur.
                </p>

                <h4><code>gpu_benchmark.rs</code></h4>
                <p>
                    Suite de benchmarks pour mesurer les performances GPU. Teste chaque module individuellement.
                </p>

                <h4><code>gpu_metrics.rs</code></h4>
                <p>
                    M√©triques de performance : ops/s, GB/s, utilisation GPU %, temp√©rature.
                    Publi√©es vers l'Observer.
                </p>

                <h4><code>gpu_telemetry.rs</code></h4>
                <p>
                    T√©l√©m√©trie GPU : envoie des statistiques anonymis√©es pour am√©liorer les performances futures.
                    Opt-in uniquement.
                </p>

                <h2>üìà Benchmarks R√©els</h2>

                <h3>Search Performance (100K fichiers, ~500 MB code)</h3>
                <pre><code>Op√©ration            | CPU      | GPU (Metal) | Speedup
---------------------|----------|-------------|--------
Grep simple          | 45.2s    | 3ms         | 15066x
Regex complexe       | 67.8s    | 8ms         | 8475x
Fuzzy search         | 12.4s    | 1.2ms       | 10333x
Full-text index      | 8.2s     | 12ms        | 683x</code></pre>

                <h3>Parsing Performance (10K fichiers TypeScript)</h3>
                <pre><code>Op√©ration            | CPU      | GPU (Metal) | Speedup
---------------------|----------|-------------|--------
Parse to AST         | 24.6s    | 156ms       | 157x
Type inference       | 52.3s    | 420ms       | 124x
Linting (ESLint)     | 18.9s    | 890ms       | 21x
Formatting           | 6.7s     | 420ms       | 15x</code></pre>

                <h2>üîß Configuration</h2>

                <h3>Activer l'acc√©l√©ration GPU</h3>
                <pre><code># V√©rifier si GPU d√©tect√©
francois gpu status

# Activer
francois config set GPU_ENABLED=true

# Choisir le backend
francois config set GPU_BACKEND=metal  # macOS (M1/M2/M3 ou Intel Iris)
francois config set GPU_BACKEND=cuda   # Linux/Windows NVIDIA
francois config set GPU_BACKEND=vulkan # Fallback cross-platform</code></pre>

                <h3>Configurer les caches</h3>
                <pre><code># Tailles des caches (en MB)
francois config set GPU_CACHE_L1_SIZE=512   # VRAM
francois config set GPU_CACHE_L2_SIZE=2048  # RAM
francois config set GPU_CACHE_L3_SIZE=10240 # Disk

# Activer/d√©sactiver les caches
francois config set GPU_CACHE_ENABLED=true</code></pre>

                <h3>Tuning avanc√©</h3>
                <pre><code># Nombre de threads GPU (work groups)
francois config set GPU_WORK_GROUPS=256

# Taille des buffers
francois config set GPU_BUFFER_SIZE=16MB

# Profiling (dev only)
francois config set GPU_PROFILING=true</code></pre>

                <h2>üêõ Troubleshooting</h2>

                <div class="callout callout-warning">
                    <h5>‚ö†Ô∏è GPU non d√©tect√©</h5>
                    <p><strong>macOS</strong> : Assurez-vous d'avoir macOS 11+ (Big Sur). Metal est natif, pas de drivers n√©cessaires.</p>
                    <p><strong>Linux NVIDIA</strong> : Installez <code>nvidia-cuda-toolkit</code> : <code>sudo apt install nvidia-cuda-toolkit</code></p>
                    <p><strong>Windows NVIDIA</strong> : Installez CUDA Toolkit 12.0+ depuis nvidia.com</p>
                </div>

                <h3>Out of Memory (VRAM)</h3>
                <pre><code># R√©duire les caches
francois config set GPU_CACHE_L1_SIZE=256

# R√©duire la taille des buffers
francois config set GPU_BUFFER_SIZE=8MB</code></pre>

                <h3>Performance plus lentes que CPU</h3>
                <p>
                    Sur de tr√®s petits projets (&lt;1000 fichiers), le GPU peut √™tre plus lent √† cause de l'overhead des transferts CPU‚ÜîGPU.
                    L'acc√©l√©ration GPU brille sur les projets moyens √† gros (&gt;10K fichiers).
                </p>

                <h2>üî¨ Limitations Actuelles</h2>
                <ul>
                    <li><strong>Windows AMD</strong> : Support Vulkan uniquement (pas de ROCm pour l'instant)</li>
                    <li><strong>Integrated GPUs</strong> : Performances limit√©es sur GPU int√©gr√©s faibles (&lt;256 cores)</li>
                    <li><strong>Memory</strong> : N√©cessite minimum 2 GB VRAM pour performances optimales</li>
                </ul>

                <div class="callout callout-info">
                    <h5>üöÄ Roadmap</h5>
                    <p>Fonctionnalit√©s GPU √† venir :</p>
                    <ul>
                        <li>Support ROCm (AMD) sur Linux/Windows</li>
                        <li>Semantic code search avec embeddings sur GPU</li>
                        <li>AI-assisted refactoring sur GPU</li>
                        <li>Real-time collaboration avec CRDT sur GPU</li>
                    </ul>
                </div>
            </div>

            <div class="docs-nav-buttons">
                <a href="../getting-started.html" class="docs-nav-button">
                    <span>‚Üê Pr√©c√©dent</span>
                    <span>Installation</span>
                </a>
                <a href="francois-observer.html" class="docs-nav-button next">
                    <span>Suivant ‚Üí</span>
                    <span>Fran√ßois Observer</span>
                </a>
            </div>
        </main>

        <!-- Table of Contents -->
        <aside class="docs-toc">
            <h4>Sur cette page</h4>
            <ul>
                <li><a href="#vue-densemble">Vue d'ensemble</a></li>
                <li><a href="#architecture-35-modules">Architecture 35 Modules</a></li>
                <li><a href="#benchmarks-reels">Benchmarks R√©els</a></li>
                <li><a href="#configuration">Configuration</a></li>
                <li><a href="#troubleshooting">Troubleshooting</a></li>
                <li><a href="#limitations">Limitations</a></li>
            </ul>
        </aside>
    </div>
</body>
</html>
